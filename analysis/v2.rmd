---
title: Predicting recall RT with 2AFC RT (v2.0)
date: Mar 3, 2021
---

```{r setup, include=FALSE}
source("setup.r")
```

```{r}
version = 'v2.0'
all_trials = read_csv(glue('../data/{version}/simple-recall.csv')) %>% 
    filter(!practice) %>% 
    mutate(
        response_type = factor(response_type, 
            levels=c("correct", "intrusion", "other", "timeout", "empty"),
            # labels=c("Correct", "Intrusion", "Other")
        ),
        word_type = factor(word_type, 
            levels=c("low", "high"), labels=c("Low", "High")),
        total_time = rt + type_time,
        correct = response_type == "correct"
    ) %>% mutate(
        base_rt = rt,
        rt = typing_rt
    )

afc = read_csv(glue('../data/{version}/afc.csv')) 
afc %<>% 
    mutate(
        round = rep(1:3, each=20, times=length(unique(all_trials$wid))),
        log_afc_rt = log(rt)
    ) %>% 
    filter(rt > 100) %>%   # mispresses or recording errors
    filter(!practice)

x1 = afc %>% 
    group_by(wid, word) %>% 
    summarise(afc_accuracy = mean(correct))

x2 = afc %>% 
    filter(correct) %>% 
    group_by(wid, word) %>% 
    summarise(afc_rt = mean(rt))

all_trials = inner_join(all_trials, inner_join(x1, x2))
```



### Exclusions

```{r}

trials = all_trials %>% group_by(wid) %>% filter(mean(correct) > 0.25)
n_exclude = length(unique(all_trials$wid)) - length(unique(trials$wid))
N = length(unique(trials$wid))

nt = nrow(trials)
max_rt = with(trials, mean(rt, na.rm=TRUE) + 3 * sd(rt, na.rm=TRUE))
trials = filter(trials, rt < max_rt)
n_trial = nrow(trials)
n_drop_rt = nt - n_trial

trials %<>% mutate(
    log_afc_rt = log(afc_rt),
    log_recall_rt = log(rt)
)
```

- Excluding `r n_exclude` participants who gave incorrect resonses on fewer than 25% of recall trials, leaving `r N` participants in the analysis.
- Dropping `r n_drop_rt` recall trials with reaction times over more than 3 sds above the mean (more than `r round(max_rt/1000, 1)` seconds), leaving `r n_trial` trials in the analysis.


## AFC RT -> Recall RT

We want to see if the reaction time on 2AFC trials for a given word are predictive of reaction time for the same word in the recall task.

```{r}
ggplot(trials, aes(log_afc_rt, log_recall_rt)) + 
    geom_point() + 
    geom_smooth(method=lm, se=F)

ggplot(trials, aes(log_afc_rt, log_recall_rt)) + 
    stat_summary_bin() + 
    geom_smooth()

trials %>% with(lm(log_recall_rt ~ log_afc_rt)) %>% summ
```
This looks promising, but it could be driven by individual differences. We need to see the effect within individuals.

```{r}
ggplot(trials, aes(log_afc_rt, log_recall_rt, group=wid)) + 
    geom_smooth(method=lm, se=F)
trials %>% with(lmer(log_recall_rt ~ log_afc_rt + (1|wid))) %>% summ
```

Looks like we still see a positive relationship. We can visualize it more
clearly by applying participant-wise mean centering:

```{r}
trials %<>% group_by(wid) %>% mutate(
    centered_log_recall_rt = log_recall_rt - mean(log_recall_rt),
    centered_log_afc_rt = log_afc_rt - mean(log_afc_rt),
) %>% ungroup()

ggplot(trials, aes(centered_log_afc_rt, centered_log_recall_rt, group=wid)) + 
    geom_smooth(method=lm, se=F)
```

And here is the distribution of slopes (with 95% confidence intervals).
```{r}
effects = trials %>% 
    nest(-wid) %>% 
    mutate(
        fit = map(data, ~ 
            lm(log_recall_rt ~ log_afc_rt, data=.) %>% 
            tidy(conf.int = T)
        )
    ) %>% 
    unnest(fit) %>% 
    filter(term == 'log_afc_rt') %>% 
    arrange(estimate)

ggplot(effects, aes(reorder(wid, estimate), estimate)) + 
    geom_point() +
    geom_errorbar(aes(ymin=conf.low , ymax=conf.high)) +
    geom_hline(yintercept=0, color="red") +
    labs(x="slope(log_recall_rt ~ log_afc_rt)", y="participant") +
    coord_flip()

prop_slope_positive = with(effects, mean(estimate > 0))
```

`r round(100 * prop_slope_positive)`% of participants have a positive slope. This is a good sign, but it's still
not great. The estimates are super noisy so it's hard to know how much of this is real. Here's a similar plot with the correlation.

```{r}
trials %>%
    group_by(wid) %>% 
    summarise(estimate=cor(log_recall_rt, log_afc_rt)) %>% 
    ggplot(aes(reorder(wid, estimate), estimate)) + 
        geom_point() +
        geom_hline(yintercept=0, color="red") + 
        labs(y="correlation(log_recall_rt, log_afc_rt)", x="participant") +
        coord_flip()
```


## AFC accuracy

```{r}

ggplot(trials, aes(afc_accuracy, log_recall_rt)) + 
    stat_summary()

trials %>% with(lm(log_recall_rt ~ afc_accuracy)) %>% summ

```
This looks promising, but it turns out this one is driven entirely by individual differences (each line is a participant).
Mixed effects regression shows no effect of 2AFC trials, especially when we account for RT on the correct 2AFC trials.

```{r}
trials %>%
    group_by(wid, afc_accuracy) %>% 
    summarise(log_recall_rt=mean(log_recall_rt)) %>% 
    ggplot(aes(afc_accuracy, log_recall_rt, group=wid)) + 
        geom_line() + theme(legend.position = "none")

trials %>% with(lmer(log_recall_rt ~ afc_accuracy + (1|wid))) %>% summ
trials %>% with(lmer(log_recall_rt ~ afc_accuracy + log_afc_rt + (1|wid))) %>% summ
```

## Time course

```{r}
ggplot(afc, aes(round, log_afc_rt)) + 
    stat_summary()
```

2AFC RT goes down, as we would expect.

```{r}
df = afc %>%
    select(wid, word, round, log_afc_rt) %>%
    pivot_wider(names_from=round, values_from=log_afc_rt, names_prefix='log_afc_rt') %>% 
    inner_join(select(trials, wid, word, log_recall_rt))

lmer(log_recall_rt ~  log_afc_rt1 + log_afc_rt2 + log_afc_rt3 + (1|wid), data=df) %>% summ
```

The slope appears to be constant over rounds.

```{r}
select(df, starts_with('log')) %>% cor(use="pairwise.complete.obs") %>% kable
```

But the correlation is higher in rounds 2 and 3. (Look at the last column in the correlation matrix)



# Word type effects

## Accuracy

### All participants (before exclusion)
```{r}
all_trials %>% group_by(wid) %>% summarise(accuracy=mean(correct)) %>%
    ggplot(aes(accuracy)) + 
        geom_histogram(binwidth=.1)
```

```{r}
ggplot(all_trials, aes(fill=response_type, x=word_type)) +
     geom_histogram(stat="count") + response_type_colors
```


### Good participants (after exclusion)

```{r}
ggplot(trials, aes(fill=response_type, x=word_type)) +
     geom_histogram(stat="count") + response_type_colors
```

```{r, echo=TRUE}
glmer(correct ~ word_type + (1|wid), data=trials, family=binomial) %>% summ
```


## Reaction time

### Aggregate

```{r}
ggplot(trials, aes(x=response_type, y=rt, color=word_type)) + 
    stat_summary(fun.data=mean_se, geom="pointrange", position = position_dodge(width = 0.1)) + 
    theme(legend.position=c(0.2, 0.9)) + word_type_colors
trials %>% group_by(response_type, word_type) %>% summarise(rt = mean(rt)) %>% kable
```

### By participant

```{r}
grouped = trials %>% 
    group_by(wid, word_type, response_type) %>% 
    summarise(across(where(is.numeric), mean)) %>% 
    ungroup()

ggplot(grouped, aes(x=word_type, y=rt, color=response_type, group=response_type)) + 
    geom_line(alpha=0.3, size=1, aes(group=interaction(response_type, wid))) +
    stat_summary(fun.data=mean_se, geom="pointrange") + 
    stat_summary(fun.data=mean_se, geom="line", size=1) + 
    facet_wrap(~response_type) +
    response_type_colors + theme(legend.position="none")

ggplot(filter(grouped, response_type == "correct"), aes(x=word_type, y=rt, color=response_type, group=response_type)) + 
    geom_line(alpha=0.3, size=1, aes(group=interaction(response_type, wid))) +
    stat_summary(fun.data=mean_se, geom="pointrange") + 
    stat_summary(fun.data=mean_se, geom="line", size=1) + 
    response_type_colors + theme(legend.position="none")
```

```{r}
prop = grouped %>%
    filter(response_type == "correct") %>%
    group_by(wid, word_type) %>%
    summarise(rt=mean(rt)) %>% 
    pivot_wider(names_from=word_type, values_from=rt) %>% 
    with(round(mean(Low > High) * 100))
## prop
```

`r prop`% of participants respond faster on high memorability trials (including only correct response trials).


### Stats

```{r, echo=TRUE}
lmer(rt ~ word_type + (1|wid), data=trials) %>% summ
```

```{r, echo=TRUE}
lmer(rt ~ word_type * response_type + (1|wid), data=trials) %>% summ
```

```{r, echo=TRUE}
lmer(rt ~ word_type + (1|wid), data=subset(trials, correct)) %>% summ
```

```{r, echo=TRUE}
lmer(log_recall_rt ~ word_type + (1|wid), data=subset(trials, correct)) %>% summ
```

## Typing time

```{r}
ggplot(trials, aes(x=response_type, y=type_time, color=word_type)) + 
    stat_summary(fun.data=mean_se, geom="pointrange", position = position_dodge(width = 0.1)) + 
    theme(legend.position=c(0.2, 0.9)) + word_type_colors
trials %>% group_by(response_type, word_type) %>% summarise(type_time = mean(type_time)) %>% kable
```

```{r, echo=TRUE}
lm(type_time ~ word_type, data=subset(trials, correct)) %>% summ
```

## Total response time

```{r}
ggplot(trials, aes(x=response_type, y=rt+type_time, color=word_type)) + 
    stat_summary(fun.data=mean_se, geom="pointrange", position = position_dodge(width = 0.1)) + 
    theme(legend.position=c(0.2, 0.9)) + word_type_colors
trials %>% group_by(response_type, word_type) %>% summarise(total_time = mean(rt+type_time)) %>% kable
```

```{r, echo=TRUE}
lm(rt + type_time ~ word_type, data=subset(trials, correct)) %>% summ
``` 

## Check response coding

#### Responses classified as "other" (incorrect but not intrusion)
```{r}
trials %>% filter(word == response)  %>% with(all(correct)) %>% stopifnot
trials %>% filter(response_type == "other") %>% select(word, response) %>% kable
```

#### Non-exact matches classified as correct
```{r}
trials %>% filter(correct & word != response) %>% select(word, response) %>% kable
```

