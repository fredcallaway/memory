---
title: Giving up (v6.0 - v6.1)
date: "`r Sys.Date()`"
author: "fredcallaway"
output:
  rmdformats::robobook:
    code_folding: hide
    self_contained: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
    results='asis', warning=FALSE, message=FALSE, fig.width=5, fig.height=4, fig.align="center"
)
source("setup.r")

VERSIONS = c('v6.3')
# VERSIONS = c('v4.0')
# VERSIONS = c('v2.0', 'v2.0B')

load_data = function(type) {
    VERSIONS %>% 
    map(~ read_csv(glue('../data/{.x}/{type}.csv'))) %>% 
    bind_rows
}

pretest = load_data('simple-recall') %>% 
    filter(!practice) %>% 
    mutate(
        response_type = factor(response_type, 
            levels=c("correct", "intrusion", "other", "timeout", "empty"),
            # labels=c("Correct", "Intrusion", "Other")
        ),
        total_time = rt + type_time,
        correct = response_type == "correct"
    ) %>% mutate(
        base_rt = rt,
        rt = typing_rt
    )

all_trials = load_data('simple-recall-penalized') %>% 
    filter(!practice) %>% 
    mutate(
        response_type = factor(response_type, 
            levels=c("correct", "intrusion", "other", "timeout", "empty"),
            # labels=c("Correct", "Intrusion", "Other")
        ),
        total_time = rt + type_time,
        correct = response_type == "correct"
    ) %>% mutate(
        base_rt = rt,
        rt = typing_rt
    )

strengths = pretest %>% 
    filter(block == max(block)) %>% 
    mutate(strength =  5 * correct - log(rt)) %>%
    group_by(wid, word) %>% 
    summarise(strength = mean(strength)) %>%
    group_by(wid) %>%
    mutate(strength = zscore(strength))

all_trials = all_trials %>% left_join(strengths)

# x1 = afc %>% 
#     group_by(wid, word) %>% 
#     summarise(afc_accuracy = mean(correct))

# x2 = afc %>% 
#     filter(correct) %>% 
#     group_by(wid, word) %>% 
#     summarise(afc_rt = mean(rt))

# all_trials = inner_join(all_trials, inner_join(x1, x2))
```

# Data

Here we are analyzing simple cued-recall trials where we incentivized participants
to respond quickly and not respond incorrectly (allowing them to pass instead).

As of Dec 17, 2021, this link will bring you to the test trials (but it might change later).
https://memorygame29.herokuapp.com/?skip=4

### Exclusions

```{r}
trials = all_trials
# trials = all_trials %>% group_by(wid) %>% filter(mean(correct) > 0.25)
# trials = trials %>%
#     filter(rt > 50) %>%
#     group_by(wid) %>% 
#     filter(n() >= 35) %>% 
#     filter(between(mean(response_type == "empty"), .2, .8))


n_exclude = length(unique(all_trials$wid)) - length(unique(trials$wid))
N = length(unique(trials$wid))

nt = nrow(trials)
max_rt = with(trials, mean(rt, na.rm=TRUE) + 5 * sd(rt, na.rm=TRUE))
# trials = filter(trials, rt < max_rt)
n_trial = nrow(trials)
n_drop_rt = nt - n_trial

# trials %<>% mutate(
#     log_afc_rt = log(afc_rt),
#     recall_rt = rt,
#     log_recall_rt = log(rt)
# )

trials$name = "Human"

trials = trials %>% 
    group_by(wid) %>% 
    mutate(rt_z = zscore(rt)) %>% 
    ungroup()

# trials %>% select(wid, rt, correct, afc_rt, afc_accuracy) %>% write_csv("../model/tofit/simple.csv")
```

- Excluding `r n_exclude` participants who gave orrect resonses on fewer than 25% of recall trials or responded in under 50ms on more than one trial (indicating a recording error), leaving `r N` participants in the analysis.



## Response types

```{r}
trials %>% 
    count(wid, response_type) %>% 
    pivot_wider(names_from=response_type, values_from=n) %>% 
    replace(is.na(.), 0) %>% 
    select(wid, correct, empty, timeout, intrusion, other) %>% 
    arrange(correct) %>% kable
```

- there are very few errors (incorrect responses)
- most participants provide empty responses frequently
- some provide empty responses almost all the time
- two out of ten never give an empty response and time out frequently,
  suggesting that they didn't understand the instructions

## Reaction time on success trials

```{r}
trials %>% 
    filter(response_type == "correct") %>% 
    regress(strength, rt_z) #plot
```

- faster correct responses with higher strength, as we've seen before

## Reaction time on empty trials (FOK)

```{r}
trials %>% 
    filter(response_type == "empty") %>% 
    regress(strength, rt_z) #plot
```

- slower empty responses with higher strength! (trending)
- NOTE: I had previously analyzed raw (non-zscore) RT and there was nothing (small negative effect)

## Split by participant

```{r,fig.width=WIDTH, fig.height=HEIGHT}
trials %>% 
    group_by(wid) %>% 
    mutate(
        rt_z = zscore(rt), 
        mean_correct = mean(response_type == "empty"),
        participant = glue("{100*round(mean_correct, 2)}% empty({wid})")
    ) %>% 
    ungroup() %>% 
    mutate(participant=fct_reorder(participant, mean_correct)) %>% 
    filter(response_type %in% c("correct", "empty")) %>% 
    ggplot(aes(strength, rt_z, color=participant)) + 
    geom_smooth(method="lm", level=0) +
    facet_wrap(~response_type) +
    labs(x="Memory Strength", y="Reaction Time (z-scored)")
```

- the effect for correct trials is pretty reliable
- the effect for empty trials only comes out in participants who give empty responses between 
  40% and 75% of the time
