---
title: Optimal giving up in single-cue recall (final pilot)
date: "`r Sys.Date()`"
author: "fredcallaway"
output:
  rmdformats::robobook:
    code_folding: hide
    self_contained: true
---


```{r setup, include=FALSE}

knitr::opts_chunk$set(
    results='asis', warning=FALSE, message=FALSE, fig.width=5, fig.height=4, fig.align="center"
)
source("setup.r")

# VERSIONS = c('v6.5', 'v6.5B', 'v6.5C', 'v6.6', 'v6.7', 'v6.8')
VERSIONS = c('v6.5', 'v6.5B', 'v6.5C')

load_data = function(type) {
    VERSIONS %>% 
    map(~ 
        read_csv(glue('../data/{.x}/{type}.csv'), col_types = cols()) %>% 
        mutate(version = .x)
    ) %>% 
    bind_rows
}

all_pretest = load_data('simple-recall') %>% 
    # filter(!practice) %>% 
    # group_by(wid) %>% filter(n() == 74) %>% ungroup %>%
    mutate(
        response_type = factor(response_type, 
            levels=c("correct", "intrusion", "other", "timeout", "empty"),
            # labels=c("Correct", "Intrusion", "Other")
        ),
        total_time = rt + type_time,
        correct = response_type == "correct",
    ) %>% mutate(
        base_rt = rt,
        rt = typing_rt
    )

all_trials = load_data('simple-recall-penalized') %>% 
    # filter(!practice) %>% 
    mutate(
        response_type = factor(response_type, 
            levels=c("correct", "intrusion", "other", "timeout", "empty"),
            # labels=c("Correct", "Intrusion", "Other")
        ),
        total_time = rt + type_time,
        correct = response_type == "correct",
        skip = response_type == "empty"
    ) %>% mutate(
        base_rt = rt,
        rt = typing_rt
    )

pal = scale_colour_manual(values=c(
    `0`="brown1",
    `0.5`="darkgoldenrod1",
    `1`="limegreen"
), aesthetics=c("fill", "colour"))

```
# Data

Here we are analyzing simple cued-recall trials where we incentivized participants
to respond quickly and not respond incorrectly (allowing them to pass instead).

As of Feb 2, 2022, this link will bring you to the test trials (but it might change later).
https://memorygame29.herokuapp.com/?skip=4

Version(s): `r paste(VERSIONS)`

### Exclusions

```{r}
all_trials$name = 'Human'

excl = all_trials %>% 
    group_by(wid) %>%
    summarise(correct_rate=mean(correct), skip_rate=mean(skip)) %>% 
    mutate(keep=skip_rate < .9)

keep = excl %>% filter(keep) %>% with(wid)

trials = all_trials %>% filter(wid %in% keep)

pretest = all_pretest %>% 
    filter(wid %in% keep) %>% 
    filter(block == max(block)) %>% 
    rename(pre_correct = correct) %>% 
    mutate(pre_logrt = if_else(pre_correct, log(rt), NaN)) %>% 
    mutate(raw_strength = -if_else(pre_correct, log(rt), log(15000))) %>% 
    group_by(wid, word) %>% 
    summarise(across(c(pre_correct, pre_logrt, raw_strength), mean, na.rm=T)) %>%
    group_by(wid) %>%
    mutate(across(c(pre_correct, pre_logrt, raw_strength), zscore, .names="{.col}_z"))

trials = left_join(trials, pretest) %>% 
    filter(response_type %in% c("correct","empty")) %>% 
    group_by(wid, response_type) %>% 
    mutate(rt_z=zscore(rt)) %>% 
    group_by(wid)
```

- Dropping `r sum(!excl$keep)` participants who skipped more than 90% of critical trials.
- This leaves `r length(keep)` participants in the analysis.

# Subjective judgements

The most direct replication of Costermans et al.: How does reaction time depend
on explicit reports of confidence and feeling of knowing, given after a
response is made?

## Confidence for correct responses

<blockquote>
    <h4>How confident are you in your response?</h4>
    <p>Press a number between 1 and 5.</p>

    <b>1</b>&nbsp;&nbsp; I am not at all sure my response is correct<br>
    <b>2</b>&nbsp;&nbsp; I am not so sure my response is correct<br>
    <b>3</b>&nbsp;&nbsp; I am more or less sure my response is correct<br>
    <b>4</b>&nbsp;&nbsp; I am nearly sure my response is correct<br>
    <b>5</b>&nbsp;&nbsp; I am absolutely sure my response is correct<br>
</blockquote>


```{r}
trials %>%  #plot
    filter(correct) %>% 
    regress(judgement, rt_z, bins=0, bin_range=1) +
    stat_summary(fun.data=mean_cl_boot, size=.2) +
    xlab("Confidence Judgement")
```

## FOK for empty responses

<blockquote>
    <h4>How much do you feel that you know the word?</h4>
    <p>Press a number between 1 and 5.</p>

    <b>1</b>&nbsp;&nbsp; I am absolutely sure I do not know the word<br>
    <b>2</b>&nbsp;&nbsp; I am rather sure I do not know the word<br>
    <b>3</b>&nbsp;&nbsp; I have a vague impression I know the word<br>
    <b>4</b>&nbsp;&nbsp; I am rather sure I know the word<br>
    <b>5</b>&nbsp;&nbsp; I am absolutely sure I know the word<br>
</blockquote>

```{r}
trials %>%  #plot
    filter(skip) %>% 
    regress(judgement, rt_z, bins=0, bin_range=1) +
    stat_summary(fun.data=mean_cl_boot, size=.2) +
    xlab("FOK Judgement")
```

# Objective memory strength measure

We can now ask the same thing, using performance on the pretest as an
objective measure of the strength of each memory.

```{r}
trials %>% #plot
    filter(correct) %>% 
    regress(pre_correct, rt_z, bins=0, bin_range=1) +
    stat_summary(fun.data=mean_cl_boot, size=.2) +
    xlab("Pretest Accuracy")
```

We consistently see faster responses for higher-strength cues. This is unsurprising.

## Reaction time on skips

```{r}
trials %>% #plot
    filter(skip) %>% 
    regress(pre_correct, rt_z, bins=0, bin_range=1) +
    stat_summary(fun.data=mean_cl_boot, size=.2) +
    xlab("Pretest Accuracy")
```